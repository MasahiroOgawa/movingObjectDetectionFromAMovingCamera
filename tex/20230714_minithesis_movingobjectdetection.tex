\documentclass[10pt, twocolumn]{article}
\usepackage{simpleConference}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{url,hyperref}

\begin{document}

\title{Moving Object Detection from a Moving Camera}

\author{Masahiro Ogawa \\
  \\
  Yamashita An Lab,
  Department of Precision Engineering,
  University of Tokyo, Japan\\
  Mini thesis\\
  \today
  \\
  \\
  ogawa@robot.t.u-tokyo.ac.jp}

\maketitle
\thispagestyle{empty}

\begin{abstract}
  We develop the state of the art accuracy moving object detection from a moving camera.
  The basic idea of our algorithm is if the camera is moving straight forward, we extract moving object as strange flow considering the computed focus of expansion, other wise we assume the camera is rotating and extract moving objects as undominant flow area. At the same time, to reduce false positives, we incorporate optical flow and semantic segmentation information.
  Our approach accomplish state of the art accuracy on our qualitative evaluation.
\end{abstract}


\section{Introduction}
Separating moving and static objects is very important for real environment applications.
For example, such applications include obstacle avoidance for autonomous vehicles, and scene understanding for assistant robots.


\section{Real-rated Work}
There have been several papers on moving object detection from a moving camera.
One famous paper is "Moving Object Detection with a Moving Camera: A Comprehensive Review" by Chapelle et al\cite{chapel2020moving}. They categorized moving object detection methods, but did not create a ranking. Another paper, "Wasabi of Moving Object Detection Methods" by Chapelle et al., categorized methods and provided rankings. The highest-ranking method, M unit 2, used grayscale monocular video and combined three channels: grayscale image, background subtraction image, and flux mask. However, this method only works for slightly moving cameras and cannot handle large camera movements.

Other papers in the category of moving object detection with a moving camera include a review paper and the best method, "Semi-Supervised Video Segmentation on Davist." The best method in this category is "hmmn," which requires human interaction and tracking, which is not ideal.

Next, we searched for individual methods. The first one is a feature-based approach called "Moving Object Detection under a Moving Camera: Background Subtraction and Recognition" by Win Long Song et al. This method uses the orientation of the optical flow between adjacent frames and calculates the background orientation field. The motion saliency is obtained by the difference between the reconstructed background orientation and the region orientation.

The second method is a homography-based approach called "Multiple Moving Object Detection on Simultaneous Tracking from Time-Varying Background." This method estimates the camera rotation using computer vision techniques and solves the question when both the camera's focal length and rotation are unknown. However, this method assumes a fixed focal length.

The next method is a state-of-the-art deep learning approach called "On Super Bus Moving Object Detection: Context of Information Separation." They use an adversarial network with flow area. The generator tries to create a mask that is hard to estimate inside the wall, while the in-painter tries to estimate the floor inside the mask and compute the information reduction rate. The generator creates the foreground mask, which contains different information from outside the mask. This method performed well on their dataset, but had some issues when tested on a different dataset, such as false positives in low-textured areas and overly large moving object regions.

\section{Proposed Method}
Our proposed method involves combining flow and texture cues for moving object detection from a moving camera. We found that estimating camera motion and optical flow simultaneously is necessary. We compute the optical flow and estimate the camera's focal length using a popular optical flow model. We assume a small area for computing the focal length as the camera is assumed to be rotating. We use the dominant flow in the background as the background flow and extract the different orientation flows for moving objects. By computing the focal length and having a sufficiently large area, we use the outliers as moving objects and combine them with segmentation information to extract the final moving object region. Our approach does not involve refining the rotation as we cannot estimate both the focal length and rotation simultaneously. We use the RunSAC algorithm to compute the focal length and rotation for each candidate.

\section{Evaluation}

\subsection{Qualitative Evaluation}
We used our own dataset to compare the results of our method with state-of-the-art methods, including Rosario Network. Our approach successfully extracted moving object areas compared to the failure of Rosario Network in large floor areas.

\subsection{Quantitative Evaluation}
For quantitative evaluation, we used the Davis dataset, which is commonly used for moving object detection. However, we have not yet finished the implementation, so there are no quantitative evaluation results available at this time.

\section{Summary}
In this paper, we have presented a state-of-the-art accuracy method for extracting moving objects from a moving camera. Our method combines flow and segmentation information to achieve better results compared to existing state-of-the-art methods like Rosario Network.

\section{Future Work}
In future work, we plan to:

\begin{itemize}
  \item Estimate counter motion using deep neural networks instead of using traditional methods.
  \item Utilize nerve object scene representation to extract security representation and objective information.
  \item Apply this method to 3D reconstruction.
\end{itemize}

\bibliographystyle{abbrv}
\bibliography{4dreconstruction}

\end{document}
